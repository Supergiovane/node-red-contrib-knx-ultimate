<script type="text/markdown" data-help-name="knxUltimateAI">
Dieser Node hört **alle KNX-Telegramme** des ausgewählten KNX-Ultimate-Gateways mit, erstellt Statistiken, erkennt einfache Anomalien und kann (optional) ein LLM um eine menschenlesbare Analyse bitten.

## Funktionen
- Führt eine rollierende Historie der KNX-Telegramme (von KNX Ultimate dekodiert) im RAM.
- Gibt periodisch oder auf Anfrage **Traffic-Summaries** aus (Top-Gruppenadressen, Ereignistypen, Rate).
- Erzeugt **Anomalie-Events** (zu hohe Bus-Rate, Spam auf GA, „Flapping“).
- Optional: LLM-Abfrage über den Befehl `ask`.

## Ausgänge
1. **Summary/Stats** (`msg.payload` ist JSON)
2. **Anomalien** (`msg.payload` ist JSON mit Details)
3. **AI Assistant** (`msg.payload` ist Textantwort; enthält `msg.summary`)

## Befehle (Input-Pin)
Sende eine Nachricht mit `msg.topic`:
- `summary` (oder leer): Summary sofort ausgeben
- `reset`: Historie und Zähler löschen
- `ask`: LLM befragen (nutzt Summary + recent traffic)

Für `ask` die Frage in `msg.prompt` (empfohlen) oder in `msg.payload` (String) senden.

## LLM-Kontext (bessere Antworten)
Beim Befehl `ask` kann der Node optional zusätzlichen Kontext an das LLM senden:
- **Flow-Inventar**: Liste der KNX-Ultimate Nodes aus deinen Node-RED Flows (hilft beim Zuordnen der Telegramme zur Logik).
- **Doku-Auszüge**: relevante Ausschnitte aus Help/README/Beispielen (und `docs/wiki`, falls verfügbar).

## Hinweise
- Wenn du das LLM aktivierst, werden Bus-Informationen an den konfigurierten Endpoint gesendet. Für „on-premise“ Nutzung einen lokalen Provider verwenden.
- Für OpenAI nur den API-Key einfügen (beginnt mit `sk-`). **Nicht** `Bearer ...` oder die ganze `Authorization:`-Zeile einfügen.
</script>
